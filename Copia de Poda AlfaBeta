{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1estvqB74cwKwPUHWb0M8RuI3ZJ_jANKU","timestamp":1681481160514},{"file_id":"1qfRVo6yV7n82YPJwyu1pcWqd7wzbXWeb","timestamp":1654218445309}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Inteligencia Artificial\n","Universidad del Cauca\n","Facultad de Ingeniería Electrónica y Telecomunicaciones\n","Ember Ubeimar Martinez\n","\n","Russell S., Norvig P., Inteligencia Artificial: Un Enfoque Moderno, ‎ALHAMBRA, 2nd edición (1 Septiembre 2004),\\\\978-8420540030"],"metadata":{"id":"bPk-yQ5156eP"}},{"cell_type":"code","source":["import copy\n","import itertools\n","import random\n","from collections import namedtuple\n","import numpy as np"],"metadata":{"id":"HoXNtc01p-yb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GameState():\n","  def __init__(self, board, utility=None, nivel=0):\n","    self.__board=board\n","    self.__utility=utility\n","    self.__nivel=nivel\n","\n","  @property\n","  def board(self):\n","    return self.__board\n","\n","  @board.setter\n","  def board(self, value):\n","    self.__board = value\n","  \n","  @property\n","  def utility(self):\n","    return self.__utility\n","\n","  @utility.setter\n","  def utility(self, value):\n","    self.__utility = value\n","  \n","  @property\n","  def nivel(self):\n","    return self.__nivel\n","\n","  @nivel.setter\n","  def nivel(self, value):\n","    self.__nivel = value"],"metadata":{"id":"Bn562howA0By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Game(object):\n","    # Identificar cuales son los movimientos o jugadas posibles de un jugador\n","    def actions(self, state):\n","        raise NotImplementedError\n","\n","    # Ejecutar un movimiento o jugada y retornar el nuevo estado\n","    def result(self, state, move):\n","        raise NotImplementedError\n","\n","    # Calcular la función de utilidad\n","    def utility(self, state):\n","        raise NotImplementedError\n","\n","    # Condición de parada (profundidad, ganador )\n","    def terminal_test(self, state):\n","        return not self.actions(state)\n","        \n","    # Ejecutar el juego\n","    def play_game(self, *players):\n","       raise NotImplementedError\n"],"metadata":{"id":"flfIuX9EpVkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3g_gxcoSpOqc"},"outputs":[],"source":["def alpha_beta_search(state, game):\n","    # Functions used by alpha_beta\n","    def max_value(state, alpha, beta):\n","        if game.terminal_test(state):\n","            return game.utility(state)\n","        v = -np.inf\n","        for a in game.actions(state,1):\n","            v = max(v, min_value(game.result(state, a,1), alpha, beta))\n","            if v >= beta:\n","                return v\n","            alpha = max(alpha, v)\n","        return v\n","\n","    def min_value(state, alpha, beta):\n","        if game.terminal_test(state):\n","            return game.utility(state)\n","        v = np.inf\n","        for a in game.actions(state,2):\n","            v = min(v, max_value(game.result(state, a,2), alpha, beta))\n","            if v <= alpha:\n","                return v\n","            beta = min(beta, v)\n","        return v\n","\n","    # Body of alpha_beta_search:\n","    best_score = -np.inf\n","    beta = np.inf\n","    best_action = None\n","    for a in game.actions(state,1):\n","        newstate=game.result(state, a,1)\n","        print(a,newstate.board)\n","        v = min_value(newstate, best_score, beta)\n","        if v > best_score:\n","            best_score = v\n","            best_action = a\n","    print('Best Action',best_action)\n","    return best_action"]},{"cell_type":"code","source":["import copy\n","import random as rnd\n","class TicTacToe():\n","  def __init__(self):\n","    self.table = [-1]*9\n","    self.nivel = 4\n","  \n","  def actions(self, state, player):\n","    board=state.board\n","    actions=[]\n","    for i, value in enumerate(board):\n","      if value==-1:\n","        actions.append(i)\n","    return actions\n","\n","  def result(self, state, action, player):    \n","    board=state.board\n","    newboard=copy.deepcopy(board)\n","    newboard[action]=player\n","    n=state.nivel+1\n","    newstate=GameState(newboard, nivel=n)\n","    return newstate\n","  \n","  def utility(self, state):\n","    board=state.board\n","    return rnd.randint(-10,10)\n","\n","\n","  def terminal_test(self, state):\n","    if state.nivel==self.nivel or self.checkTicTacToe(state):\n","      return True\n","    else:\n","      return False\n","  \n","  def checkTicTacToe(self, state):\n","    board=state.board\n","    if self.checkTicTacToeRow(board):\n","      return True\n","    elif self.checkTicTacToeCol(board):\n","      return True\n","    elif self.checkTicTacToeDiag(board):\n","      return True\n","    else:\n","      return False\n","\n","\n","  def checkTicTacToeRow(self,board):\n","    for i in range(0,len(board),3):\n","      ctr=set(board[i:i+3])\n","      if len(ctr)==1 and (-1 not in ctr):\n","        return True\n","    return False\n","\n","  def checkTicTacToeCol(self,board):\n","    for i in range(0,3,1):\n","      ctr=set(board[i::3])\n","      if len(ctr)==1 and (-1 not in ctr):\n","        return True\n","    return False\n","  \n","  def checkTicTacToeDiag(self,board):\n","    ctr=set(board[::4])\n","    if len(ctr)==1 and (-1 not in ctr):\n","      return True\n","    ctr=set(board[2:-1:2])\n","    if len(ctr)==1and (-1 not in ctr):\n","      return True\n","    return False\n","\n","\n","\n"],"metadata":{"id":"NVGZa6rDtue0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"B7d32g9TzKBU"}},{"cell_type":"code","source":["tictactoe=TicTacToe()\n","state=GameState([2,-1,-1,-1,1,2,-1,-1,1])\n","comp=alpha_beta_search(state,tictactoe)\n","print(comp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yG94y8gxy5SM","executionInfo":{"status":"ok","timestamp":1681481287056,"user_tz":300,"elapsed":216,"user":{"displayName":"ARLEX FABIAN GALINDEZ RIVERA","userId":"07539792810102976383"}},"outputId":"ec5c6388-fe74-4e6e-a1cb-29b0dc5ce90c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 [2, 1, -1, -1, 1, 2, -1, -1, 1]\n","2 [2, -1, 1, -1, 1, 2, -1, -1, 1]\n","3 [2, -1, -1, 1, 1, 2, -1, -1, 1]\n","6 [2, -1, -1, -1, 1, 2, 1, -1, 1]\n","7 [2, -1, -1, -1, 1, 2, -1, 1, 1]\n","Best Action 7\n","7\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ni6oCXR4NWUN"},"execution_count":null,"outputs":[]}]}